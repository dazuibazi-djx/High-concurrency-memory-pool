# High-concurrency-memory-pool
  我当前的项目目标是实现一个高并发环境下的高效内存池，其原型参考了 Google 开源的 tcmalloc（Thread-Caching Malloc），通过学习阅读这个模型提炼出了核心的部分，实现了这个项目。tcmalloc 的核心思想是为每个线程维护本地缓存，从而减少线程间竞争，提高内存分配与释放的效率。基于这一思路，我们在保留其关键机制的基础上，对框架进行了简化，实现了一个轻量级的内存池，以有效解决多线程场景下的内存分配瓶颈问题。
#### 简单介绍
  在高并发环境下，当有大量并发请求的服务中，程序会产生极其频繁的小对象分配与释放。每一次直接调用操作系统或通用分配器（如 malloc/free）不仅包含用户态与内核态之间的上下文切换，还要操纵复杂的全局或进程级数据结构，这在高频次路径上会带来可观的 CPU 开销和延迟。
此外，频繁且不规则的分配/释放模式会引发内存碎片问题：外部碎片（可用空闲内存分散成不连续小块，无法满足较大连续请求）和内部碎片（为对齐或按固定粒度分配导致分配块中有未使用空间）。碎片不仅降低内存利用率，还可能在长期运行后导致内存请求失败或触发昂贵的整理/回收操作，从而进一步拉高尾延迟（tail latency）。
学术与工程界已有多种为并发场景专门设计的分配器来解决上述问题：例如 Hoard 研究指出，通过线程感知的设计可以同时避免内存“爆炸性增长”与伪共享，从而实现可扩展的多线程分配；TCMalloc 将“线程缓存 + 中央缓存 + 页面堆”的三层模型实践化，大幅减少小对象分配的锁争用；jemalloc 强调在并发环境下的碎片避免与可观测/可调优能力，这些工作为简化复现与改进提供了坚实的设计基础。
通过复现并简化顶级分配器的核心架构来掌握高性能内存管理思想，并提供一个可供学习与实验的实现。本项目延续了池化技术（就是程序先向系统申请过量的资源，然后⾃⼰管理，以备不时之需）。本文的主要贡献如下：
1) 提出并实现简化的三层缓存：ThreadCache（线程缓存），CentralCache（中心缓存）、PageCache（页缓存）。
2) 在线程缓存中使用 TLS申请内存不需要加锁，每个线程独享一个Cache、中心缓存使用桶锁，使用均衡算法实现多个线程中更均衡的按需调度的⽬的、页缓存回收central cache满⾜条件的span对象，并且合并相邻的⻚，组成更⼤的⻚，缓解内存碎⽚的问题。
3) 给出完整性能评估与碎片分析，比较系统 malloc 与 本项目的申请释放内存的时间。

#### 使用说明
将整个代码进行下载，其中文件夹为核心的代码部分，然后如果是想要在自己的电脑上运行的话，需要下载zip压缩吧，使用vs2019打开concurrent-MemoryPool.sln即可运行。然后在BenchMark 中提供了测试案例。进行测试多线程的模式。

